{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethan Zheng, 05/08/2019\n",
    "\n",
    "### Background and introduction\n",
    "Every syllable in English must have a vowel (a monophthong or a diphthong) as its nucleus. An interesting problem would be to count how many syllables a word has, and group the phonemes into their corresponding syllables. The easier version of this problem is when we are given the IPA expression of the word, where we can accurately examine the phonemes. The harder problem is when we are given the orthographical form of a word, can we still use a program to count the syllables accountably. If this is made possible, can we separate the syllables and match them to their corresponding IPA snippets?\n",
    "\n",
    "### A first problem: Getting a dictionary of words with their corresponding IPA forms\n",
    "NLTK has provided a corpus that fits this requirement very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 123455\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "dictionary = nltk.corpus.cmudict.dict()\n",
    "print(\"Dictionary size: \", end = \"\")\n",
    "print(len(dictionary))\n",
    "\n",
    "wordList = ['fastidious', 'liability', 'automatic', \n",
    "            'thanks', 'trace', 'finish', 'decline', \n",
    "            'forbid', 'injection', 'difficulty'\n",
    "           ]\n",
    "#             , 'craftsman', 'replacement', 'presidential', \n",
    "#             'virgin', 'advantage', 'complain', 'investment',\n",
    "#             'bay', 'tear', 'orientation', 'file', 'slot', \n",
    "#             'barrel', 'contraction', 'encourage', 'multiply', \n",
    "#             'variety', 'variation', 'likely', 'complication', \n",
    "#             'opera', 'behave', 'economy', 'dish', 'photograph',\n",
    "#             'rotation', 'stimulation', 'bottom', 'curve', \n",
    "#             'minority', 'way', 'innovation', 'exaggerate', \n",
    "#             'thesis', 'hardship', 'mechanism', 'lamp', 'salesperson', \n",
    "#             'inflate', 'page', 'dog', 'rank', 'strict', 'physical',\n",
    "#             'space', 'factory', 'prison','enthusiasm', 'flash', \n",
    "#             'session', 'smash', 'communication', 'stick', 'degree', \n",
    "#             'question', 'trust', 'photocopy', 'canvas', 'fun', \n",
    "#             'cool', 'slide', 'penalty', 'corn', 'deliver', \n",
    "#             'intensify', 'neighbor', 'hope', 'exception', 'mayor', \n",
    "#             'forget', 'neck', 'afford', 'mutter', 'great', \n",
    "#             'forward', 'tablet', 'glasses', 'bed', 'lazy', \n",
    "#             'receipt', 'reach', 'lawyer', 'commemorate', 'elephant',\n",
    "#             'advertising', 'dialogue', 'food', 'feather', \n",
    "#             'treasurer', 'chaos']\n",
    "\n",
    "# Randomly generated wordList from https://randomwordgenerator.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count syllables by vowels\n",
    "Since each syllable is marked by a vowel as its kernel, the number if syllables is the number of vowels. In the list of phonemes the dictionary gives us, consonants are one or two characters long, and vowels are three characters long with the last one being the level of stress. This gives us a very handy way to sort out vowels from consonants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastidious\tSyllables: 4\t['F', 'AE0', 'S', 'T', 'IH1', 'D', 'IY0', 'AH0', 'S']\n",
      "liability\tSyllables: 5\t['L', 'AY2', 'AH0', 'B', 'IH1', 'L', 'IH0', 'T', 'IY0']\n",
      "automatic\tSyllables: 4\t['AO2', 'T', 'AH0', 'M', 'AE1', 'T', 'IH0', 'K']\n",
      "thanks\t\tSyllables: 1\t['TH', 'AE1', 'NG', 'K', 'S']\n",
      "trace\t\tSyllables: 1\t['T', 'R', 'EY1', 'S']\n",
      "finish\t\tSyllables: 2\t['F', 'IH1', 'N', 'IH0', 'SH']\n",
      "decline\t\tSyllables: 2\t['D', 'IH0', 'K', 'L', 'AY1', 'N']\n",
      "forbid\t\tSyllables: 2\t['F', 'ER0', 'B', 'IH1', 'D']\n",
      "injection\tSyllables: 3\t['IH0', 'N', 'JH', 'EH1', 'K', 'SH', 'AH0', 'N']\n",
      "difficulty\tSyllables: 4\t['D', 'IH1', 'F', 'AH0', 'K', 'AH0', 'L', 'T', 'IY0']\n"
     ]
    }
   ],
   "source": [
    "def countSyllables(phonemeList):\n",
    "    count = 0\n",
    "    for phoneme in phonemeList:\n",
    "        if(len(phoneme) == 3):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "for word in wordList:\n",
    "    phonemes = dictionary[word][0]\n",
    "    if(len(word) <= 7):\n",
    "        print(word, end = '\\t\\t')\n",
    "    else:\n",
    "        print(word, end = '\\t')\n",
    "    print(\"Syllables: \", end = \"\")\n",
    "    print(countSyllables(phonemes), end = '\\t')\n",
    "    print(phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group phonemes into their corresponding syllables\n",
    "\n",
    "#### General Rules (updated):\n",
    "1. Each syllable has a vowel as nucleus.\n",
    "2. If a vowel is followed by another vowel, the second vowel forms an onsetless syllable.\n",
    "3. If a vowel appears at the word initial, it forms an onsetless syllable.\n",
    "4. The consonant cluster that appears before a vowel is the onset of that syllable. According to maximal onset principle, we always want to maximize the length of an onset given that it's possible.\n",
    "5. After we get the onset, the remaining of the consonant cluster is the coda of the previous syllable.\n",
    "\n",
    "#### Maximal onset principle:\n",
    "1. strike /stɹaɪk/: The onset is /stɹ/.\n",
    "2. swim /swɪm/: The onset is /sw/.\n",
    "3. construct /ˈkɑn.stɹʌkt/: The onset of the second syllable is /stɹ/ because /nstɹ/ is impossible.\n",
    "4. eyebrow /ˈaɪˌbɹaʊ/: The onset of the second syllable is /br/ because it is allowed in English.\n",
    "5. ghastly /ˈɡæs(t).li/: The onset of the second syllable is /l/ because /tl/ and /stl/ are impossible. \n",
    "\n",
    "#### Possible consonant clusters for onsets in English:\n",
    "(Data acquired from http://usefulenglish.ru/phonetics/practice-consonant-clusters, with modification)\n",
    "1. /pl/, /pɹ/, /bl/, /bɹ/,\n",
    "2. /tɹ/, /dɹ/,\n",
    "3. /kl/, /kɹ/, /gl/, /gɹ/,\n",
    "4. /fl/, /fɹ/,\n",
    "5. /ʃɹ/, /θɹ/,\n",
    "6. /sk/, /skɹ/,\n",
    "7. /sl/, /sm/, /sn/,\n",
    "8. /sp/, /spl/, /spɹ/,\n",
    "9. /st/, /stɹ/,\n",
    "10. /sw/, /tw/, /dw/, /kw/, /skw/, /gw/\n",
    "\n",
    "#### Taking these into account, I have a program designed as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastidious\t[['F', 'AE0'], ['S', 'T', 'IH1'], ['D', 'IY0'], ['AH0', 'S']]\n",
      "liability\t[['L', 'AY2'], ['AH0'], ['B', 'IH1'], ['L', 'IH0'], ['T', 'IY0']]\n",
      "automatic\t[['AO2'], ['T', 'AH0'], ['M', 'AE1'], ['T', 'IH0', 'K']]\n",
      "thanks\t\t[['TH', 'AE1', 'NG', 'K', 'S']]\n",
      "trace\t\t[['T', 'R', 'EY1', 'S']]\n",
      "finish\t\t[['F', 'IH1'], ['N', 'IH0', 'SH']]\n",
      "decline\t\t[['D', 'IH0'], ['K', 'L', 'AY1', 'N']]\n",
      "forbid\t\t[['F', 'ER0'], ['B', 'IH1', 'D']]\n",
      "injection\t[['IH0', 'N'], ['JH', 'EH1', 'K'], ['SH', 'AH0', 'N']]\n",
      "difficulty\t[['D', 'IH1'], ['F', 'AH0'], ['K', 'AH0', 'L'], ['T', 'IY0']]\n",
      "strike\t\t[['S', 'T', 'R', 'AY1', 'K']]\n",
      "swim\t\t[['S', 'W', 'IH1', 'M']]\n",
      "construct\t[['K', 'AH0', 'N'], ['S', 'T', 'R', 'AH1', 'K', 'T']]\n",
      "eyebrow\t\t[['AY1'], ['B', 'R', 'AW2']]\n",
      "ghastly\t\t[['G', 'AE1', 'S', 'T'], ['L', 'IY0']]\n"
     ]
    }
   ],
   "source": [
    "onsetClusters = [\n",
    "    ['P','L'], ['P','R'], ['B','L'], ['B','R'], \n",
    "    ['T','R'], ['D','R'], \n",
    "    ['K','L'], ['K','R'], ['G','L'], ['G','R'], \n",
    "    ['F','L'], ['F','R'], \n",
    "    ['SH','R'], ['TH','R'], \n",
    "    ['S','K'], ['S','K','R'], \n",
    "    ['G','L'], ['G','R'], \n",
    "    ['S','L'], ['S','M'], ['S','N'], \n",
    "    ['S','P'], ['S','P','L'], ['S','P','R'], \n",
    "    ['S','T'], ['S','T','R'], \n",
    "    ['S','W'], ['T','W'], ['D','W'], ['K','W'], ['S','K','W'], ['G','W']\n",
    "]\n",
    "\n",
    "def listEquals(l1, l2):\n",
    "    if(len(l1) != len(l2)):\n",
    "        return False\n",
    "    for i in range(len(l1)):\n",
    "        if(l1[i] != l2[i]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def isValidOnset(cluster):\n",
    "    for valid in onsetClusters:\n",
    "        if(listEquals(cluster, valid)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def groupPhonemes(phonemeList):\n",
    "    grouped = []\n",
    "    temp = []\n",
    "    prevPhoneme = ''\n",
    "    isWordInitial = True\n",
    "    for phoneme in phonemeList:\n",
    "        if len(phoneme) == 3:\n",
    "            if not isWordInitial:\n",
    "                if len(prevPhoneme) != 3:\n",
    "                    cluster = temp[-3:]\n",
    "                    if(isValidOnset(cluster)):\n",
    "                        del temp[-3:]\n",
    "                    else:\n",
    "                        cluster = temp[-2:]\n",
    "                        if(isValidOnset(cluster)):\n",
    "                            del temp[-2:]\n",
    "                        else:\n",
    "                            cluster = temp[-1:]\n",
    "                            del temp[-1:]\n",
    "                    grouped.append(temp)\n",
    "                    temp = cluster\n",
    "                else:\n",
    "                    grouped.append(temp)\n",
    "                    temp = []\n",
    "            else:\n",
    "                isWordInitial = False\n",
    "        temp.append(phoneme)\n",
    "        prevPhoneme = phoneme\n",
    "    grouped.append(temp)\n",
    "    return grouped\n",
    "    \n",
    "exampleList = wordList + ['strike','swim','construct','eyebrow','ghastly']\n",
    "\n",
    "for word in exampleList:\n",
    "    phonemes = dictionary[word][0]\n",
    "    if(len(word) <= 7):\n",
    "        print(word, end = '\\t\\t')\n",
    "    else:\n",
    "        print(word, end = '\\t')\n",
    "    print(groupPhonemes(phonemes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "\n",
    "This block of code compares the syllables returned by direct count (by the number of vowels) and the number of phoneme groups in the list of syllables returned by the grouping function.\n",
    "\n",
    "As you can see, the grouping function gives the correct number of syllables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastidious\tDirect Count: 4\t\tGroup Count: 4\t\tMatch: True\n",
      "liability\tDirect Count: 5\t\tGroup Count: 5\t\tMatch: True\n",
      "automatic\tDirect Count: 4\t\tGroup Count: 4\t\tMatch: True\n",
      "thanks\t\tDirect Count: 1\t\tGroup Count: 1\t\tMatch: True\n",
      "trace\t\tDirect Count: 1\t\tGroup Count: 1\t\tMatch: True\n",
      "finish\t\tDirect Count: 2\t\tGroup Count: 2\t\tMatch: True\n",
      "decline\t\tDirect Count: 2\t\tGroup Count: 2\t\tMatch: True\n",
      "forbid\t\tDirect Count: 2\t\tGroup Count: 2\t\tMatch: True\n",
      "injection\tDirect Count: 3\t\tGroup Count: 3\t\tMatch: True\n",
      "difficulty\tDirect Count: 4\t\tGroup Count: 4\t\tMatch: True\n",
      "strike\t\tDirect Count: 1\t\tGroup Count: 1\t\tMatch: True\n",
      "swim\t\tDirect Count: 1\t\tGroup Count: 1\t\tMatch: True\n",
      "construct\tDirect Count: 2\t\tGroup Count: 2\t\tMatch: True\n",
      "eyebrow\t\tDirect Count: 2\t\tGroup Count: 2\t\tMatch: True\n",
      "ghastly\t\tDirect Count: 2\t\tGroup Count: 2\t\tMatch: True\n"
     ]
    }
   ],
   "source": [
    "for word in exampleList:\n",
    "    phonemes = dictionary[word][0]\n",
    "    if(len(word) <= 7):\n",
    "        print(word, end = '\\t\\t')\n",
    "    else:\n",
    "        print(word, end = '\\t')\n",
    "    syllableCount = countSyllables(phonemes)\n",
    "    grouped = groupPhonemes(phonemes)\n",
    "    print('Direct Count: ', end = '')\n",
    "    print(syllableCount, end = '\\t\\tGroup Count: ')\n",
    "    print(len(grouped), end = '\\t\\tMatch: ')\n",
    "    print(len(grouped) == syllableCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next problem: Matching the grouped syllables to orthographical form\n",
    "\n",
    "In order to do this, we need to create a dictionary that maps spellings fragments to phonemes. We first make a copy of our corpus and delete the stress marking for the sake of convenience. Then we make a set of all phonemes that the corpus contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH']\n",
      "Elements count: 39\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "dictionaryCopy = copy.deepcopy(dictionary)\n",
    "phonemeSet = set()\n",
    "\n",
    "for key, values in dictionaryCopy.items():\n",
    "    for possibleValue in values:\n",
    "        for phoneme in possibleValue:\n",
    "            if len(phoneme) == 3:\n",
    "                phoneme = phoneme[:2]\n",
    "            phonemeSet.add(phoneme)\n",
    "\n",
    "print(sorted(phonemeSet))\n",
    "print(\"Elements count: \", end = \"\")\n",
    "print(len(phonemeSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know what phonemes there are. So we can start to make a simple dictionary that maps phonemes to spelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemeDict = {\n",
    "    'AA': ['oo','ou','u','o'], \n",
    "    'AE': ['ai','a'], \n",
    "    'AH': ['eur','our','ur','re','or','oo','ou','er','ar','a','u','o','i','e',''],\n",
    "    'AO': ['au','ho','o','a'], \n",
    "    'AW': ['ough','ow','ou'], \n",
    "    'AY': ['eigh','eye','igh','ie','uy','ye','ai','is','i','y'], \n",
    "    'B' : ['bb','b'], \n",
    "    'CH': ['tch','ch','tu','ti','te'], \n",
    "    'D' : ['dd','ed','d'], \n",
    "    'DH': ['th'], \n",
    "    'EH': ['eo','ei','ae','ay','ie','ai','ea','e','u','a'], \n",
    "    'ER': ['eur','our','er','ar','ir','or','ur','re'], \n",
    "    'EY': ['eigh','ea','ay','ai','a'], \n",
    "    'F' : ['ff','ph','gh','lf','ft','f'], \n",
    "    'G' : ['gue','gg','gh','gu','g'], \n",
    "    'HH': ['wh','h'], \n",
    "    'IH': ['ie','ui','a','i','e','o','u','y'], \n",
    "    'IY': ['ee','ea','ey','oe','ie','ei','eo','ay','e','i','y'], \n",
    "    'JH': ['dge','di','gg','ge','g','j'], \n",
    "    'K' : ['que','ch','cc','ke','lk','qu','ck','q','k','c','x'], \n",
    "    'L' : ['ll','le','l'], \n",
    "    'M' : ['mm','mb','mn','lm','m'], \n",
    "    'N' : ['nn','kn','gn','pn','ne','n'], \n",
    "    'NG': ['ngue','ng','n'], \n",
    "    'OW': ['ough','eau','oa','oe','ow','oo','eu','o'], \n",
    "    'OY': ['ouy','oi','oy'], \n",
    "    'P' : ['pp','p'], \n",
    "    'R' : ['rr','wr','rh','r'], \n",
    "    'S' : ['ss','sc','ps','st','ce','se','c','s'], \n",
    "    'SH': ['sci','sh','ce','ci','si','ch','ti','s'], \n",
    "    'T' : ['tt','th','ed','t'], \n",
    "    'TH': ['th'], \n",
    "    'UH': [], \n",
    "    'UW': ['ough','oeu','oo','oe','ew','ue','ui','ou','o','u'], \n",
    "    'V' : ['ph','ve','v','f'], \n",
    "    'W' : ['wh','w','u','o'], \n",
    "    'Y' : ['y','i','j',''], \n",
    "    'Z' : ['zz','ss','ze','se','z','s','x'], \n",
    "    'ZH': ['si','s','z']\n",
    "}\n",
    "\n",
    "# Data modified from https://www.dyslexia-reading-well.com/support-files\n",
    "#/the-44-phonemes-of-english.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is that with a list of phoneme for the word, we iterate through all the phonemes in the list and try to fit a spelling to it. For each phoneme, we pick the first one available in the list of spelling it corresponds to, and try to fit it. If the choice is correct, we proceed on to the next phoneme. Otherwise, when it doesn't have any spelling that fits, we will go back to the previous phoneme and try the next one in the list, until all the phonemes are successfully fitted onto the word. This recursive method is called backtracking, and is widely used on puzzle solving functions like a Sudoku solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastidious\n",
      "[('F', 'f'), ('AE0', 'a'), ('S', 's'), ('T', 't'), ('IH1', 'i'), ('D', 'd'), ('IY0', 'i'), ('AH0', 'ou'), ('S', 's')]\n",
      "liability\n",
      "[('L', 'l'), ('AY2', 'i'), ('AH0', 'a'), ('B', 'b'), ('IH1', 'i'), ('L', 'l'), ('IH0', 'i'), ('T', 't'), ('IY0', 'y')]\n",
      "automatic\n",
      "[('AO2', 'au'), ('T', 't'), ('AH0', 'o'), ('M', 'm'), ('AE1', 'a'), ('T', 't'), ('IH0', 'i'), ('K', 'c')]\n",
      "thanks\n",
      "[('TH', 'th'), ('AE1', 'a'), ('NG', 'n'), ('K', 'k'), ('S', 's')]\n",
      "trace\n",
      "[('T', 't'), ('R', 'r'), ('EY1', 'a'), ('S', 'ce')]\n",
      "finish\n",
      "[('F', 'f'), ('IH1', 'i'), ('N', 'n'), ('IH0', 'i'), ('SH', 'sh')]\n",
      "decline\n",
      "[('D', 'd'), ('IH0', 'e'), ('K', 'c'), ('L', 'l'), ('AY1', 'i'), ('N', 'ne')]\n",
      "forbid\n",
      "[('F', 'f'), ('ER0', 'or'), ('B', 'b'), ('IH1', 'i'), ('D', 'd')]\n",
      "injection\n",
      "[('IH0', 'i'), ('N', 'n'), ('JH', 'j'), ('EH1', 'e'), ('K', 'c'), ('SH', 'ti'), ('AH0', 'o'), ('N', 'n')]\n",
      "difficulty\n",
      "[('D', 'd'), ('IH1', 'i'), ('F', 'ff'), ('AH0', 'i'), ('K', 'c'), ('AH0', 'u'), ('L', 'l'), ('T', 't'), ('IY0', 'y')]\n",
      "strike\n",
      "[('S', 's'), ('T', 't'), ('R', 'r'), ('AY1', 'i'), ('K', 'ke')]\n",
      "swim\n",
      "[('S', 's'), ('W', 'w'), ('IH1', 'i'), ('M', 'm')]\n",
      "construct\n",
      "[('K', 'c'), ('AH0', 'o'), ('N', 'n'), ('S', 's'), ('T', 't'), ('R', 'r'), ('AH1', 'u'), ('K', 'c'), ('T', 't')]\n",
      "eyebrow\n",
      "[('AY1', 'eye'), ('B', 'b'), ('R', 'r'), ('AW2', 'ow')]\n",
      "ghastly\n",
      "[('G', 'gh'), ('AE1', 'a'), ('S', 's'), ('T', 't'), ('L', 'l'), ('IY0', 'y')]\n"
     ]
    }
   ],
   "source": [
    "def matchPhoneme(word):\n",
    "    matchList = []\n",
    "    phonemeList = dictionary[word][0]\n",
    "    matchPhonemeKernel(word, phonemeList, matchList, 0)\n",
    "    return matchList\n",
    "\n",
    "def matchPhonemeKernel(word, phonemeList, matchList, index):\n",
    "    if(index == len(phonemeList)): # base case\n",
    "        if(len(word) != 0):\n",
    "            return False\n",
    "        return True\n",
    "    phoneme = phonemeList[index]\n",
    "    phonemeWithoutStress = phoneme\n",
    "    if(len(phonemeWithoutStress) == 3):\n",
    "        phonemeWithoutStress = phonemeWithoutStress[:2]\n",
    "    for spelling in phonemeDict[phonemeWithoutStress]:\n",
    "        if(spelling == word[0:len(spelling)]):\n",
    "#             print(word)\n",
    "            matchList.append((phoneme, spelling))\n",
    "            subWord = word[len(spelling):]\n",
    "            # recursive call\n",
    "            success = matchPhonemeKernel(subWord, phonemeList, matchList, index + 1) \n",
    "            if(success): # if succeed then proceed\n",
    "                return True\n",
    "            # delete the failed attempt and try again in the next iteration\n",
    "            del matchList[len(matchList) - 1] \n",
    "    return False\n",
    "\n",
    "for word in exampleList:\n",
    "    print(word)\n",
    "    print(matchPhoneme(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The last step: Separate syllables in spelling by merging the phonemic grouping and the matching\n",
    "\n",
    "Now we have the grouping on phonemes and the matching from phonemes to spelling snippets, so the problem gets simple. We just need to simply substitute all the phonemes with their corresponding spelling snippets, and concatenate them. For different groups, we connect them with \"-\" to represent syllables. Then finally we will get a human-readable form like \"liability: li-a-bi-li-ty\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastidious\tfa-sti-di-ous\n",
      "liability\tli-a-bi-li-ty\n",
      "automatic\tau-to-ma-tic\n",
      "thanks\t\tthanks\n",
      "trace\t\ttrace\n",
      "finish\t\tfi-nish\n",
      "decline\t\tde-cline\n",
      "forbid\t\tfor-bid\n",
      "injection\tin-jec-tion\n",
      "difficulty\tdi-ffi-cul-ty\n",
      "strike\t\tstrike\n",
      "swim\t\tswim\n",
      "construct\tcon-struct\n",
      "eyebrow\t\teye-brow\n",
      "ghastly\t\tghast-ly\n",
      "\n",
      "\n",
      "Please enter another word to test the program. Enter \"Q\" to quit:\n",
      "career\n",
      "['K', 'ER0', 'IH1', 'R']\n",
      "ERROR: Empty matchlist\n",
      "2 syllables\n",
      "\n",
      "Please enter another word to test the program. Enter \"Q\" to quit:\n",
      "Q\n"
     ]
    }
   ],
   "source": [
    "def groupSpelling(word):\n",
    "    result = ''\n",
    "    phonemes = dictionary[word][0]\n",
    "    grouped = groupPhonemes(phonemes)\n",
    "    matchList = matchPhoneme(word)\n",
    "    if(len(matchList) == 0):\n",
    "        return 'ERROR: Empty matchlist'\n",
    "    index = 0\n",
    "    for group in grouped:\n",
    "        for phoneme in group:\n",
    "            result += matchList[index][1]\n",
    "            index += 1\n",
    "        result += '-'\n",
    "    result = result[:len(result) - 1]\n",
    "    return result\n",
    "\n",
    "for word in exampleList:\n",
    "    if(len(word) <= 7):\n",
    "        print(word, end = '\\t\\t')\n",
    "    else:\n",
    "        print(word, end = '\\t')\n",
    "    print(groupSpelling(word))\n",
    "    \n",
    "print('\\n')\n",
    "    \n",
    "while(True):\n",
    "    print('Please enter another word to test the program. Enter \"Q\" to quit:')\n",
    "    word = input()\n",
    "    if(word == 'Q'):\n",
    "        break\n",
    "    print(dictionary[word][0])\n",
    "    print(groupSpelling(word))\n",
    "    count = countSyllables(dictionary[word][0])\n",
    "    if(count == 1):\n",
    "        print(count, end = ' syllable\\n\\n')\n",
    "    else:\n",
    "        print(count, end = ' syllables\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this project, we start from counting syllables by the number of nucleus(vowels), and proceed to grouping phonemes into corresponding syllables. In the grouping process, we realized several principles in syllabification including maximal onset principle and the handling of onsetless syllables. By running a test we can prove the validity of the grouping by comparing the number of grouped syllables with the initial counting from nucleus. Then, by constructing a dictionary that matches phonemes to spelling snippets, we are able to run a backtracking algorithm that matches each phoneme with its corresponding spelling. Finally, with a simple substitution, we are able to break up the spelling into syllables in the way we break up phonemes.\n",
    "\n",
    "Since we approach this problem from the IPA form, it dramatically increases the program's reliability and accuracy. The only insufficiencies of this program is that it relies on the installation of the NLTK corpus and can only process existing English words. In order to increase its robustness, we also need to further add to the dictionary so that it accounts for more irregular spelling patterns. Since we use a try-match approach, adding more entries to the dictionary will have little effect on the determinism of the program. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
